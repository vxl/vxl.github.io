<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
"http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
  <title>core/vnl/algo/vnl_conjugate_gradient.cxx Source File</title>
  <link href="doxygen.css" rel="stylesheet" type="text/css" />
  <link href="tabs.css" rel="stylesheet" type="text/css" />
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
</head>
<body>
<!-- Generated by Doxygen 1.7.5.1 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
      <li><a href="globals.html"><span>File&#160;Members</span></a></li>
    </ul>
  </div>
<div class="header">
  <div class="headertitle">
<div class="title">core/vnl/algo/vnl_conjugate_gradient.cxx</div>  </div>
</div>
<div class="contents">
<a href="vnl__conjugate__gradient_8cxx.html">Go to the documentation of this file.</a><div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 <span class="comment">// This is core/vnl/algo/vnl_conjugate_gradient.cxx</span>
<a name="l00002"></a>00002 <span class="preprocessor">#ifdef VCL_NEEDS_PRAGMA_INTERFACE</span>
<a name="l00003"></a>00003 <span class="preprocessor"></span><span class="preprocessor">#pragma implementation</span>
<a name="l00004"></a>00004 <span class="preprocessor"></span><span class="preprocessor">#endif</span>
<a name="l00005"></a>00005 <span class="preprocessor"></span><span class="comment">//:</span>
<a name="l00006"></a>00006 <span class="comment">// \file</span>
<a name="l00007"></a>00007 <span class="comment">// \author Geoffrey Cross, Oxford RRG</span>
<a name="l00008"></a>00008 <span class="comment">// \date   15 Feb 99</span>
<a name="l00009"></a>00009 <span class="comment">//</span>
<a name="l00010"></a>00010 <span class="comment">//-----------------------------------------------------------------------------</span>
<a name="l00011"></a>00011 <span class="preprocessor">#include &quot;<a class="code" href="vnl__conjugate__gradient_8h.html" title="real function minimization">vnl_conjugate_gradient.h</a>&quot;</span>
<a name="l00012"></a>00012 
<a name="l00013"></a>00013 <span class="preprocessor">#include &lt;vcl_iostream.h&gt;</span>
<a name="l00014"></a>00014 
<a name="l00015"></a>00015 <span class="preprocessor">#include &lt;<a class="code" href="vnl__cost__function_8h.html" title="Vector-&gt;Real function.">vnl/vnl_cost_function.h</a>&gt;</span>
<a name="l00016"></a>00016 <span class="preprocessor">#include &lt;<a class="code" href="vnl__vector__ref_8h.html" title="vnl_vector using user-supplied storage">vnl/vnl_vector_ref.h</a>&gt;</span>
<a name="l00017"></a>00017 <span class="preprocessor">#include &lt;<a class="code" href="vnl__netlib_8h.html" title="Declare in a central place the list of symbols from netlib.">vnl/algo/vnl_netlib.h</a>&gt;</span>
<a name="l00018"></a>00018 
<a name="l00019"></a>00019 <span class="preprocessor">#if 0</span>
<a name="l00020"></a>00020 <span class="preprocessor"></span><span class="comment">// external netlib function</span>
<a name="l00021"></a>00021 <span class="keyword">extern</span> <span class="stringliteral">&quot;C&quot;</span>
<a name="l00022"></a>00022 <span class="keywordtype">int</span> cg_( <span class="keywordtype">double</span> *x,                     <span class="comment">// IO start guess</span>
<a name="l00023"></a>00023          <span class="keywordtype">double</span> *e,                     <span class="comment">// O max-norm of gradient</span>
<a name="l00024"></a>00024          <span class="keywordtype">int</span>    *it,                    <span class="comment">// O number of iterations performed</span>
<a name="l00025"></a>00025          <span class="keywordtype">double</span> *step,                  <span class="comment">// I step=0 make guess at first direction</span>
<a name="l00026"></a>00026                                         <span class="comment">// O step size along search direction for final iteration</span>
<a name="l00027"></a>00027          <span class="keywordtype">double</span> *t,                     <span class="comment">// I tolerance (iterations stop when max-norm of gradient &lt; t)</span>
<a name="l00028"></a>00028          <span class="keywordtype">int</span> *limit,                    <span class="comment">// I maximum number of iterations</span>
<a name="l00029"></a>00029          <span class="keywordtype">int</span> *n,                        <span class="comment">// I number of unknowns</span>
<a name="l00030"></a>00030          <span class="keywordtype">int</span> *<a class="code" href="vnl__vector_8h.html#a00626facb4f86efb8618a4c5f5c3c5f8">m</a>,                        <span class="comment">// I number of iterations before renormalizing (normally m=n)</span>
<a name="l00031"></a>00031          <span class="keywordtype">double</span> value( <span class="keywordtype">double</span> *x),      <span class="comment">// I value(x) is cost at x</span>
<a name="l00032"></a>00032          <span class="keywordtype">int</span> grad( <span class="keywordtype">double</span> *g,
<a name="l00033"></a>00033                    <span class="keywordtype">double</span> *x),          <span class="comment">// I grad(g,x) puts gradient into g at x</span>
<a name="l00034"></a>00034          <span class="keywordtype">int</span> both( <span class="keywordtype">double</span> *<a class="code" href="vnl__vector_8h.html#a38bf1e5e0427bdeba2b469eea9befc23">v</a>,
<a name="l00035"></a>00035                    <span class="keywordtype">double</span> *g,
<a name="l00036"></a>00036                    <span class="keywordtype">double</span> *x),          <span class="comment">// I both(v,g,x) puts value in v and gradient in g at x</span>
<a name="l00037"></a>00037          <span class="keywordtype">int</span> pre( <span class="keywordtype">double</span> *y,
<a name="l00038"></a>00038                   <span class="keywordtype">double</span> *z),           <span class="comment">// I preconditions (not necessarily needed) pre(y,z)</span>
<a name="l00039"></a>00039          <span class="keywordtype">double</span> *h );                   <span class="comment">// I space to work size h = 3*n</span>
<a name="l00040"></a>00040 <span class="preprocessor">#endif</span>
<a name="l00041"></a>00041 <span class="preprocessor"></span><span class="comment"></span>
<a name="l00042"></a>00042 <span class="comment">/////////////////////////////////////</span>
<a name="l00043"></a><a class="code" href="classvnl__conjugate__gradient.html#a9bf0f99f16af2b078d110151036cddac">00043</a> <span class="comment"></span>
<a name="l00044"></a>00044 <a class="code" href="classvnl__conjugate__gradient.html#a9bf0f99f16af2b078d110151036cddac" title="Destructor.">vnl_conjugate_gradient::~vnl_conjugate_gradient</a>()
<a name="l00045"></a>00045 {
<a name="l00046"></a>00046 }
<a name="l00047"></a><a class="code" href="classvnl__conjugate__gradient.html#ab9bb53ec1ab66e16ddbecd4b9885f840">00047</a> 
<a name="l00048"></a>00048 <span class="keywordtype">void</span> <a class="code" href="classvnl__conjugate__gradient.html#ab9bb53ec1ab66e16ddbecd4b9885f840" title="Initialize all variables.">vnl_conjugate_gradient::init</a>(<a class="code" href="classvnl__cost__function.html" title="An object that represents a function from R^n -&gt; R.">vnl_cost_function</a> &amp;f)
<a name="l00049"></a>00049 {
<a name="l00050"></a>00050   <a class="code" href="classvnl__conjugate__gradient.html#a9822571e9f4c11361e340e626ff0747b">f_</a>= &amp;f;
<a name="l00051"></a>00051   <a class="code" href="classvnl__nonlinear__minimizer.html#a1bd527616499cd8eaddbd6fe36d4cfa1">num_iterations_</a> = 0;
<a name="l00052"></a>00052   <a class="code" href="classvnl__nonlinear__minimizer.html#ad05cb2f9c1bb9c76d237e174b0943156">num_evaluations_</a> = 0;
<a name="l00053"></a>00053   <a class="code" href="classvnl__nonlinear__minimizer.html#ae1319d7d95d1ae3ab54ab3135c170953">start_error_</a> = 0;
<a name="l00054"></a>00054   <a class="code" href="classvnl__nonlinear__minimizer.html#a134feaa367bb5d8303bb70aca6e8f00c">end_error_</a> = 0;
<a name="l00055"></a>00055 }
<a name="l00056"></a>00056 <span class="comment"></span>
<a name="l00057"></a>00057 <span class="comment">///////////////////////////////////////</span>
<a name="l00058"></a><a class="code" href="classvnl__conjugate__gradient.html#ae7addb997102e6517fe1fcaed6b1f519">00058</a> <span class="comment"></span>
<a name="l00059"></a>00059 <span class="keywordtype">double</span> <a class="code" href="classvnl__conjugate__gradient.html#ae7addb997102e6517fe1fcaed6b1f519">vnl_conjugate_gradient::valuecomputer_</a>(<span class="keywordtype">double</span> *x, <span class="keywordtype">void</span>* userdata)
<a name="l00060"></a>00060 {
<a name="l00061"></a>00061   <a class="code" href="classvnl__conjugate__gradient.html" title="real function minimization.">vnl_conjugate_gradient</a>* <span class="keyword">self</span> =
<a name="l00062"></a>00062     <span class="keyword">static_cast&lt;</span><a class="code" href="classvnl__conjugate__gradient.html" title="real function minimization.">vnl_conjugate_gradient</a>*<span class="keyword">&gt;</span>(userdata);
<a name="l00063"></a>00063   <a class="code" href="classvnl__cost__function.html" title="An object that represents a function from R^n -&gt; R.">vnl_cost_function</a>* f = <span class="keyword">self</span>-&gt;f_;
<a name="l00064"></a>00064   <a class="code" href="classvnl__vector__ref.html" title="vnl_vector using user-supplied storage.">vnl_vector_ref&lt;double&gt;</a> ref_x(f-&gt;<a class="code" href="classvnl__cost__function.html#a458d150326441477a7b4422fdae2c457" title="Return the number of unknowns.">get_number_of_unknowns</a>(), x);
<a name="l00065"></a>00065 
<a name="l00066"></a>00066   <span class="keyword">self</span>-&gt;num_evaluations_++;
<a name="l00067"></a>00067 
<a name="l00068"></a>00068   <span class="keywordflow">return</span> f-&gt;<a class="code" href="classvnl__cost__function.html#a1252f15e0d7024b47410c54a78b2f1e3" title="The main function. Given the parameter vector x, compute the value of f(x).">f</a>(ref_x);
<a name="l00069"></a>00069 }
<a name="l00070"></a><a class="code" href="classvnl__conjugate__gradient.html#ae5d8e6a30c4e98cc9c8998e5d648edb6">00070</a> 
<a name="l00071"></a>00071 <span class="keywordtype">void</span> <a class="code" href="classvnl__conjugate__gradient.html#ae5d8e6a30c4e98cc9c8998e5d648edb6">vnl_conjugate_gradient::gradientcomputer_</a>(<span class="keywordtype">double</span> *g, <span class="keywordtype">double</span> *x, <span class="keywordtype">void</span>* userdata)
<a name="l00072"></a>00072 {
<a name="l00073"></a>00073   <a class="code" href="classvnl__conjugate__gradient.html" title="real function minimization.">vnl_conjugate_gradient</a>* <span class="keyword">self</span> =
<a name="l00074"></a>00074     <span class="keyword">static_cast&lt;</span><a class="code" href="classvnl__conjugate__gradient.html" title="real function minimization.">vnl_conjugate_gradient</a>*<span class="keyword">&gt;</span>(userdata);
<a name="l00075"></a>00075   <a class="code" href="classvnl__cost__function.html" title="An object that represents a function from R^n -&gt; R.">vnl_cost_function</a>* f = <span class="keyword">self</span>-&gt;f_;
<a name="l00076"></a>00076   <a class="code" href="classvnl__vector__ref.html" title="vnl_vector using user-supplied storage.">vnl_vector_ref&lt;double&gt;</a> ref_x(f-&gt;<a class="code" href="classvnl__cost__function.html#a458d150326441477a7b4422fdae2c457" title="Return the number of unknowns.">get_number_of_unknowns</a>(), x);
<a name="l00077"></a>00077   <a class="code" href="classvnl__vector__ref.html" title="vnl_vector using user-supplied storage.">vnl_vector_ref&lt;double&gt;</a> ref_g(f-&gt;<a class="code" href="classvnl__cost__function.html#a458d150326441477a7b4422fdae2c457" title="Return the number of unknowns.">get_number_of_unknowns</a>(), g);
<a name="l00078"></a>00078 
<a name="l00079"></a>00079   f-&gt;<a class="code" href="classvnl__cost__function.html#ab9980920ed2d7da166e8f69af3b449e3" title="Calculate the gradient of f at parameter vector x.">gradf</a>(ref_x, ref_g);
<a name="l00080"></a>00080 }
<a name="l00081"></a><a class="code" href="classvnl__conjugate__gradient.html#aaa2ac01170eb8daedc289e87ce9cbdbe">00081</a> 
<a name="l00082"></a>00082 <span class="keywordtype">void</span> <a class="code" href="classvnl__conjugate__gradient.html#aaa2ac01170eb8daedc289e87ce9cbdbe">vnl_conjugate_gradient::valueandgradientcomputer_</a>(<span class="keywordtype">double</span> *v, <span class="keywordtype">double</span> *g, <span class="keywordtype">double</span> *x, <span class="keywordtype">void</span>* userdata)
<a name="l00083"></a>00083 {
<a name="l00084"></a>00084   <a class="code" href="classvnl__conjugate__gradient.html" title="real function minimization.">vnl_conjugate_gradient</a>* <span class="keyword">self</span> =
<a name="l00085"></a>00085     <span class="keyword">static_cast&lt;</span><a class="code" href="classvnl__conjugate__gradient.html" title="real function minimization.">vnl_conjugate_gradient</a>*<span class="keyword">&gt;</span>(userdata);
<a name="l00086"></a>00086   <a class="code" href="classvnl__cost__function.html" title="An object that represents a function from R^n -&gt; R.">vnl_cost_function</a>* f = <span class="keyword">self</span>-&gt;f_;
<a name="l00087"></a>00087   <a class="code" href="classvnl__vector__ref.html" title="vnl_vector using user-supplied storage.">vnl_vector_ref&lt;double&gt;</a> ref_x(f-&gt;<a class="code" href="classvnl__cost__function.html#a458d150326441477a7b4422fdae2c457" title="Return the number of unknowns.">get_number_of_unknowns</a>(), x);
<a name="l00088"></a>00088   <a class="code" href="classvnl__vector__ref.html" title="vnl_vector using user-supplied storage.">vnl_vector_ref&lt;double&gt;</a> ref_g(f-&gt;<a class="code" href="classvnl__cost__function.html#a458d150326441477a7b4422fdae2c457" title="Return the number of unknowns.">get_number_of_unknowns</a>(), g);
<a name="l00089"></a>00089 
<a name="l00090"></a>00090   f-&gt;<a class="code" href="classvnl__cost__function.html#a4ea6d354b64e10f7b4d31a67c497baa7" title="Compute one or both of f and g.">compute</a>(ref_x, v, &amp;ref_g);
<a name="l00091"></a>00091 }
<a name="l00092"></a><a class="code" href="classvnl__conjugate__gradient.html#a53b10dba54a42cd25b21b2981761126a">00092</a> 
<a name="l00093"></a>00093 <span class="keywordtype">void</span> <a class="code" href="classvnl__conjugate__gradient.html#a53b10dba54a42cd25b21b2981761126a">vnl_conjugate_gradient::preconditioner_</a>( <span class="keywordtype">double</span> *out, <span class="keywordtype">double</span> *in, <span class="keywordtype">void</span>* userdata)
<a name="l00094"></a>00094 {
<a name="l00095"></a>00095   <span class="comment">// FIXME - there should be some way to set a preconditioner if you have one</span>
<a name="l00096"></a>00096   <span class="comment">// e.g. P = inv(diag(A&#39;A)) for linear least squares systems.</span>
<a name="l00097"></a>00097 
<a name="l00098"></a>00098   <a class="code" href="classvnl__conjugate__gradient.html" title="real function minimization.">vnl_conjugate_gradient</a>* <span class="keyword">self</span> =
<a name="l00099"></a>00099     <span class="keyword">static_cast&lt;</span><a class="code" href="classvnl__conjugate__gradient.html" title="real function minimization.">vnl_conjugate_gradient</a>*<span class="keyword">&gt;</span>(userdata);
<a name="l00100"></a>00100   <a class="code" href="classvnl__cost__function.html" title="An object that represents a function from R^n -&gt; R.">vnl_cost_function</a>* f = <span class="keyword">self</span>-&gt;f_;
<a name="l00101"></a>00101 
<a name="l00102"></a>00102   <span class="keywordtype">int</span> n = f-&gt;<a class="code" href="classvnl__cost__function.html#a458d150326441477a7b4422fdae2c457" title="Return the number of unknowns.">get_number_of_unknowns</a>();
<a name="l00103"></a>00103   <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i=0; i &lt; n; ++i)
<a name="l00104"></a>00104     out[i] = in[i];
<a name="l00105"></a>00105 }
<a name="l00106"></a>00106 <span class="comment"></span>
<a name="l00107"></a>00107 <span class="comment">///////////////////////////////////////</span>
<a name="l00108"></a>00108 <span class="comment"></span>
<a name="l00109"></a>00109 <span class="comment">// avoid anachronism warning from fussy compilers</span>
<a name="l00110"></a>00110 <span class="preprocessor">#ifdef VCL_SUNPRO_CC</span>
<a name="l00111"></a>00111 <span class="preprocessor"></span><span class="keyword">extern</span> <span class="stringliteral">&quot;C&quot;</span> <span class="keywordtype">double</span> vnl_conjugate_gradient__valuecomputer_( <span class="keywordtype">double</span> *x, <span class="keywordtype">void</span>* userdata)
<a name="l00112"></a>00112 {
<a name="l00113"></a>00113   <span class="keywordflow">return</span> <a class="code" href="classvnl__conjugate__gradient.html#ae7addb997102e6517fe1fcaed6b1f519">vnl_conjugate_gradient::valuecomputer_</a>(x, userdata);
<a name="l00114"></a>00114 }
<a name="l00115"></a>00115 
<a name="l00116"></a>00116 <span class="keyword">extern</span> <span class="stringliteral">&quot;C&quot;</span> <span class="keywordtype">void</span> vnl_conjugate_gradient__gradientcomputer_( <span class="keywordtype">double</span> *g, <span class="keywordtype">double</span> *x, <span class="keywordtype">void</span>* userdata)
<a name="l00117"></a>00117 {
<a name="l00118"></a>00118   <a class="code" href="classvnl__conjugate__gradient.html#ae5d8e6a30c4e98cc9c8998e5d648edb6">vnl_conjugate_gradient::gradientcomputer_</a>(g,x, userdata);
<a name="l00119"></a>00119 }
<a name="l00120"></a>00120 
<a name="l00121"></a>00121 <span class="keyword">extern</span> <span class="stringliteral">&quot;C&quot;</span> <span class="keywordtype">void</span> vnl_conjugate_gradient__valueandgradientcomputer_( <span class="keywordtype">double</span> *v, <span class="keywordtype">double</span> *g, <span class="keywordtype">double</span> *x, <span class="keywordtype">void</span>* userdata)
<a name="l00122"></a>00122 {
<a name="l00123"></a>00123   <a class="code" href="classvnl__conjugate__gradient.html#aaa2ac01170eb8daedc289e87ce9cbdbe">vnl_conjugate_gradient::valueandgradientcomputer_</a>(v,g,x, userdata);
<a name="l00124"></a>00124 }
<a name="l00125"></a>00125 
<a name="l00126"></a>00126 <span class="keyword">extern</span> <span class="stringliteral">&quot;C&quot;</span> <span class="keywordtype">void</span> vnl_conjugate_gradient__preconditioner_( <span class="keywordtype">double</span> *out, <span class="keywordtype">double</span> *in, <span class="keywordtype">void</span>* userdata)
<a name="l00127"></a>00127 {
<a name="l00128"></a>00128   <a class="code" href="classvnl__conjugate__gradient.html#a53b10dba54a42cd25b21b2981761126a">vnl_conjugate_gradient::preconditioner_</a>(out,in, userdata);
<a name="l00129"></a>00129 }
<a name="l00130"></a>00130 
<a name="l00131"></a>00131 <span class="preprocessor">#endif</span>
<a name="l00132"></a><a class="code" href="classvnl__conjugate__gradient.html#ace3fdae9646fda7afe5379eea788205f">00132</a> <span class="preprocessor"></span>
<a name="l00133"></a>00133 <span class="keywordtype">bool</span> <a class="code" href="classvnl__conjugate__gradient.html#ace3fdae9646fda7afe5379eea788205f" title="Minimize the function supplied in the constructor until convergence or failure.">vnl_conjugate_gradient::minimize</a>( <a class="code" href="classvnl__vector.html">vnl_vector&lt;double&gt;</a> &amp;x)
<a name="l00134"></a>00134 {
<a name="l00135"></a>00135   <span class="keywordtype">double</span> *xp = x.<a class="code" href="classvnl__vector.html#a672822d3a059ac09909cb32a7be004a9" title="Access the contiguous block storing the elements in the vector. O(1).">data_block</a>();
<a name="l00136"></a>00136   <span class="keywordtype">double</span> max_norm_of_gradient;
<a name="l00137"></a>00137   <span class="keywordtype">long</span> number_of_iterations;
<a name="l00138"></a>00138   <a class="code" href="classvnl__conjugate__gradient.html#a4df8c77934abc412b081f2bb96c50703">final_step_size_</a> = 0;
<a name="l00139"></a>00139   <span class="keywordtype">double</span> gradient_tolerance = <a class="code" href="classvnl__nonlinear__minimizer.html#a4107bc0936bb7b53d28d9d3fe16e5474" title="Termination tolerance on Grad(F)&#39; * F = 0.">gtol</a>;
<a name="l00140"></a>00140   <a class="code" href="classvnl__vector.html">vnl_vector&lt;double&gt;</a> workspace(<a class="code" href="classvnl__conjugate__gradient.html#a9822571e9f4c11361e340e626ff0747b">f_</a>-&gt;<a class="code" href="classvnl__cost__function.html#a458d150326441477a7b4422fdae2c457" title="Return the number of unknowns.">get_number_of_unknowns</a>()*3);
<a name="l00141"></a>00141   <span class="keywordtype">long</span> number_of_unknowns = <a class="code" href="classvnl__conjugate__gradient.html#a9822571e9f4c11361e340e626ff0747b">f_</a>-&gt;<a class="code" href="classvnl__cost__function.html#a458d150326441477a7b4422fdae2c457" title="Return the number of unknowns.">get_number_of_unknowns</a>();
<a name="l00142"></a>00142   <span class="keywordtype">long</span> error_code;
<a name="l00143"></a>00143 
<a name="l00144"></a>00144   <span class="comment">// Compute the initial value.</span>
<a name="l00145"></a>00145   <a class="code" href="classvnl__nonlinear__minimizer.html#ae1319d7d95d1ae3ab54ab3135c170953">start_error_</a> = <a class="code" href="classvnl__conjugate__gradient.html#ae7addb997102e6517fe1fcaed6b1f519">valuecomputer_</a>(xp, <span class="keyword">this</span>);
<a name="l00146"></a>00146   <a class="code" href="classvnl__nonlinear__minimizer.html#ad05cb2f9c1bb9c76d237e174b0943156">num_evaluations_</a> = 0;
<a name="l00147"></a>00147 
<a name="l00148"></a>00148   <span class="comment">// Run the conjugate gradient algorithm.</span>
<a name="l00149"></a>00149   v3p_netlib_cg_(
<a name="l00150"></a>00150        xp,
<a name="l00151"></a>00151        &amp;max_norm_of_gradient,
<a name="l00152"></a>00152        &amp;number_of_iterations,
<a name="l00153"></a>00153        &amp;<a class="code" href="classvnl__conjugate__gradient.html#a4df8c77934abc412b081f2bb96c50703">final_step_size_</a>,
<a name="l00154"></a>00154        &amp;gradient_tolerance,
<a name="l00155"></a>00155        &amp;<a class="code" href="classvnl__nonlinear__minimizer.html#a875dd6fa5b2f3e2188abff6ecd021981" title="Termination maximum number of iterations.">maxfev</a>,
<a name="l00156"></a>00156        &amp;number_of_unknowns,
<a name="l00157"></a>00157        &amp;number_of_unknowns,
<a name="l00158"></a>00158 #ifdef VCL_SUNPRO_CC
<a name="l00159"></a>00159        vnl_conjugate_gradient__valuecomputer_,
<a name="l00160"></a>00160        vnl_conjugate_gradient__gradientcomputer_,
<a name="l00161"></a>00161        vnl_conjugate_gradient__valueandgradientcomputer_,
<a name="l00162"></a>00162        vnl_conjugate_gradient__preconditioner_,
<a name="l00163"></a>00163 #<span class="keywordflow">else</span>
<a name="l00164"></a>00164        <a class="code" href="classvnl__conjugate__gradient.html#ae7addb997102e6517fe1fcaed6b1f519">valuecomputer_</a>,
<a name="l00165"></a>00165        <a class="code" href="classvnl__conjugate__gradient.html#ae5d8e6a30c4e98cc9c8998e5d648edb6">gradientcomputer_</a>,
<a name="l00166"></a>00166        <a class="code" href="classvnl__conjugate__gradient.html#aaa2ac01170eb8daedc289e87ce9cbdbe">valueandgradientcomputer_</a>,
<a name="l00167"></a>00167        <a class="code" href="classvnl__conjugate__gradient.html#a53b10dba54a42cd25b21b2981761126a">preconditioner_</a>,
<a name="l00168"></a>00168 #endif
<a name="l00169"></a>00169        workspace.data_block(),
<a name="l00170"></a>00170        <span class="keyword">this</span>,
<a name="l00171"></a>00171        &amp;error_code);
<a name="l00172"></a>00172 
<a name="l00173"></a>00173   <span class="comment">// Check for an error condition.</span>
<a name="l00174"></a>00174   <span class="keywordflow">if</span> (error_code &gt; 0)
<a name="l00175"></a>00175   {
<a name="l00176"></a>00176     <a class="code" href="classvnl__nonlinear__minimizer.html#a0c15383c3526f88012364ac342d6e7d7">failure_code_</a> = <a class="code" href="classvnl__nonlinear__minimizer.html#a6112004b90f040a90efeebe19286b908acc184b89d8bfed731cac2ed6456cc4ce">ERROR_DODGY_INPUT</a>;
<a name="l00177"></a>00177     <span class="keywordflow">if</span> (<a class="code" href="classvnl__nonlinear__minimizer.html#a6384f8c4bfa01f6ac48959cf34825623">verbose_</a>)
<a name="l00178"></a>00178     {
<a name="l00179"></a>00179       <span class="keywordflow">switch</span> (error_code)
<a name="l00180"></a>00180       {
<a name="l00181"></a>00181         <span class="keywordflow">case</span> 1:  vcl_cout &lt;&lt; <span class="stringliteral">&quot;UNABLE TO OBTAIN DESCENT DIRECTION\n&quot;</span>; <span class="keywordflow">break</span>;
<a name="l00182"></a>00182         <span class="keywordflow">case</span> 2:  vcl_cout &lt;&lt; <span class="stringliteral">&quot;THE FUNCTION DECREASES WITH NO MINIMUM\n&quot;</span>; <span class="keywordflow">break</span>;
<a name="l00183"></a>00183         <span class="keywordflow">case</span> 3:  vcl_cout &lt;&lt; <span class="stringliteral">&quot;PRECONDITIONER NOT POSITIVE DEFINITE\n&quot;</span>; <span class="keywordflow">break</span>;
<a name="l00184"></a>00184         <span class="keywordflow">case</span> 4:  vcl_cout &lt;&lt; <span class="stringliteral">&quot;UNABLE TO SATISFY ARMIJO CONDITION\n&quot;</span>; <span class="keywordflow">break</span>;
<a name="l00185"></a>00185         <span class="keywordflow">default</span>: vcl_cout &lt;&lt; <span class="stringliteral">&quot;UNKNOWN ERROR CODE\n&quot;</span>; <span class="keywordflow">break</span>;
<a name="l00186"></a>00186       }
<a name="l00187"></a>00187     }
<a name="l00188"></a>00188   }
<a name="l00189"></a>00189 
<a name="l00190"></a>00190   <span class="comment">// Compute the final value.</span>
<a name="l00191"></a>00191   <a class="code" href="classvnl__nonlinear__minimizer.html#a134feaa367bb5d8303bb70aca6e8f00c">end_error_</a>= <a class="code" href="classvnl__conjugate__gradient.html#ae7addb997102e6517fe1fcaed6b1f519">valuecomputer_</a>(xp, <span class="keyword">this</span>);
<a name="l00192"></a>00192   <a class="code" href="classvnl__nonlinear__minimizer.html#a1bd527616499cd8eaddbd6fe36d4cfa1">num_iterations_</a> = number_of_iterations;
<a name="l00193"></a>00193 
<a name="l00194"></a>00194   <span class="keywordflow">return</span> error_code == 0;
<a name="l00195"></a>00195 }
<a name="l00196"></a>00196 
<a name="l00197"></a><a class="code" href="classvnl__conjugate__gradient.html#a250496979adac12149ab567a96a69698">00197</a> 
<a name="l00198"></a>00198 <span class="keywordtype">void</span> <a class="code" href="classvnl__conjugate__gradient.html#a8479b247d8a059242de6aed4c1bcb29d">vnl_conjugate_gradient::diagnose_outcome</a>(vcl_ostream&amp; os)<span class="keyword"> const</span>
<a name="l00199"></a>00199 <span class="keyword"></span>{
<a name="l00200"></a>00200   os &lt;&lt; <span class="stringliteral">&quot;vnl_conjugate_gradient: &quot;</span>
<a name="l00201"></a>00201      &lt;&lt; <a class="code" href="classvnl__nonlinear__minimizer.html#a1bd527616499cd8eaddbd6fe36d4cfa1">num_iterations_</a>
<a name="l00202"></a>00202      &lt;&lt; <span class="stringliteral">&quot; iterations, &quot;</span>
<a name="l00203"></a>00203      &lt;&lt; <a class="code" href="classvnl__nonlinear__minimizer.html#ad05cb2f9c1bb9c76d237e174b0943156">num_evaluations_</a>
<a name="l00204"></a>00204      &lt;&lt; <span class="stringliteral">&quot; evaluations. Cost function reported error&quot;</span>
<a name="l00205"></a>00205      &lt;&lt; <a class="code" href="classvnl__conjugate__gradient.html#a9822571e9f4c11361e340e626ff0747b">f_</a>-&gt;<a class="code" href="classvnl__cost__function.html#a4410c3dd41444bfbbcbc1878910def06" title="Called when error is printed for user.">reported_error</a>(<a class="code" href="classvnl__nonlinear__minimizer.html#ae1319d7d95d1ae3ab54ab3135c170953">start_error_</a>)
<a name="l00206"></a>00206      &lt;&lt; <span class="charliteral">&#39;/&#39;</span>
<a name="l00207"></a>00207      &lt;&lt; <a class="code" href="classvnl__conjugate__gradient.html#a9822571e9f4c11361e340e626ff0747b">f_</a>-&gt;<a class="code" href="classvnl__cost__function.html#a4410c3dd41444bfbbcbc1878910def06" title="Called when error is printed for user.">reported_error</a>(<a class="code" href="classvnl__nonlinear__minimizer.html#a134feaa367bb5d8303bb70aca6e8f00c">end_error_</a>)
<a name="l00208"></a>00208      &lt;&lt; <span class="stringliteral">&quot; . Final step size = &quot;</span> &lt;&lt; <a class="code" href="classvnl__conjugate__gradient.html#a4df8c77934abc412b081f2bb96c50703">final_step_size_</a>
<a name="l00209"></a>00209      &lt;&lt; vcl_endl;
<a name="l00210"></a>00210 }
<a name="l00211"></a><a class="code" href="classvnl__conjugate__gradient.html#a8479b247d8a059242de6aed4c1bcb29d">00211</a> 
<a name="l00212"></a>00212 <span class="keywordtype">void</span> <a class="code" href="classvnl__conjugate__gradient.html#a8479b247d8a059242de6aed4c1bcb29d">vnl_conjugate_gradient::diagnose_outcome</a>()<span class="keyword"> const</span>
<a name="l00213"></a>00213 <span class="keyword"></span>{
<a name="l00214"></a>00214   <a class="code" href="classvnl__conjugate__gradient.html#a8479b247d8a059242de6aed4c1bcb29d">diagnose_outcome</a>(vcl_cout);
<a name="l00215"></a>00215 }
</pre></div></div>
</div>


<hr class="footer"/><address class="footer"><small>
Generated on Wed May 1 2013 17:31:00 for core/vnl by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.7.5.1
</small></address>

</body>
</html>
