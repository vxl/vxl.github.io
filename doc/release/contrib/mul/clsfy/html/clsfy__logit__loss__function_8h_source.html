<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
"http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
  <title>contrib/mul/clsfy/clsfy_logit_loss_function.h Source File</title>
  <link href="doxygen.css" rel="stylesheet" type="text/css" />
  <link href="tabs.css" rel="stylesheet" type="text/css" />
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
</head>
<body>
<!-- Generated by Doxygen 1.7.5.1 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
      <li><a href="globals.html"><span>File&#160;Members</span></a></li>
    </ul>
  </div>
<div class="header">
  <div class="headertitle">
<div class="title">contrib/mul/clsfy/clsfy_logit_loss_function.h</div>  </div>
</div>
<div class="contents">
<a href="clsfy__logit__loss__function_8h.html">Go to the documentation of this file.</a><div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 <span class="comment">// This is mul/clsfy/clsfy_logit_loss_function.h</span>
<a name="l00002"></a>00002 <span class="preprocessor">#ifndef clsfy_logit_loss_function_h_</span>
<a name="l00003"></a>00003 <span class="preprocessor"></span><span class="preprocessor">#define clsfy_logit_loss_function_h_</span>
<a name="l00004"></a>00004 <span class="preprocessor"></span><span class="comment">//:</span>
<a name="l00005"></a>00005 <span class="comment">// \file</span>
<a name="l00006"></a>00006 <span class="comment">// \brief Loss function for logit of linear classifier</span>
<a name="l00007"></a>00007 <span class="comment">// \author TFC</span>
<a name="l00008"></a>00008 
<a name="l00009"></a>00009 <span class="preprocessor">#include &lt;<a class="codeRef" doxygen="core_vnl.tag:../../../../core/vnl/html" href="../../../../core/vnl/html/vnl__cost__function_8h.html">vnl/vnl_cost_function.h</a>&gt;</span>
<a name="l00010"></a>00010 <span class="preprocessor">#include &lt;<a class="codeRef" doxygen="contrib_mul_mbl.tag:../../../../contrib/mul/mbl/html" href="../../../../contrib/mul/mbl/html/mbl__data__wrapper_8h.html">mbl/mbl_data_wrapper.h</a>&gt;</span>
<a name="l00011"></a>00011 
<a name="l00012"></a>00012 <span class="comment">//: Loss function for logit of linear classifier.</span>
<a name="l00013"></a>00013 <span class="comment">//  For vector v&#39; = (b w&#39;) (ie b=y[0], w=(y[1]...y[n])), computes</span>
<a name="l00014"></a>00014 <span class="comment">//  r(v) - (1/n_eg)sum log[(1-minp)logit(c_i * (b+w.x_i)) + minp]</span>
<a name="l00015"></a>00015 <span class="comment">//</span>
<a name="l00016"></a>00016 <span class="comment">// This is the sum of log prob of correct classification (+regulariser)</span>
<a name="l00017"></a>00017 <span class="comment">// which should be minimised to train the classifier.</span>
<a name="l00018"></a>00018 <span class="comment">//</span>
<a name="l00019"></a>00019 <span class="comment">// Note: Regularisor only important to deal with case where perfect</span>
<a name="l00020"></a>00020 <span class="comment">// classification possible, where scaling v would always increase f(v).</span>
<a name="l00021"></a>00021 <span class="comment">// Plausible choice of regularisor is clsfy_quad_regulariser (below)</span>
<a name="l00022"></a><a class="code" href="classclsfy__logit__loss__function.html">00022</a> <span class="keyword">class </span><a class="code" href="classclsfy__logit__loss__function.html" title="Loss function for logit of linear classifier.">clsfy_logit_loss_function</a> : <span class="keyword">public</span> <a class="codeRef" doxygen="core_vnl.tag:../../../../core/vnl/html" href="../../../../core/vnl/html/classvnl__cost__function.html">vnl_cost_function</a>
<a name="l00023"></a>00023 {
<a name="l00024"></a>00024 <span class="keyword">private</span>:
<a name="l00025"></a><a class="code" href="classclsfy__logit__loss__function.html#aade4916237fbab45c6b1c1f2e1a6ba90">00025</a>   <a class="codeRef" doxygen="contrib_mul_mbl.tag:../../../../contrib/mul/mbl/html" href="../../../../contrib/mul/mbl/html/classmbl__data__wrapper.html">mbl_data_wrapper&lt;vnl_vector&lt;double&gt;</a> &gt;&amp; <a class="code" href="classclsfy__logit__loss__function.html#aade4916237fbab45c6b1c1f2e1a6ba90">x_</a>;
<a name="l00026"></a>00026 
<a name="l00027"></a>00027   <span class="comment">//: c[i] = -1 or +1, indicating class of x[i]</span>
<a name="l00028"></a><a class="code" href="classclsfy__logit__loss__function.html#a8742b33fff526dae2c343614cf9e2cfd">00028</a>   <span class="keyword">const</span> <a class="codeRef" doxygen="core_vnl.tag:../../../../core/vnl/html" href="../../../../core/vnl/html/classvnl__vector.html">vnl_vector&lt;double&gt;</a> &amp; <a class="code" href="classclsfy__logit__loss__function.html#a8742b33fff526dae2c343614cf9e2cfd" title="c[i] = -1 or +1, indicating class of x[i].">c_</a>;
<a name="l00029"></a>00029 
<a name="l00030"></a>00030   <span class="comment">//: Min probability (avoids log(zero))</span>
<a name="l00031"></a><a class="code" href="classclsfy__logit__loss__function.html#a7f9996082faccc77b71a60cc8068d502">00031</a>   <span class="keywordtype">double</span> <a class="code" href="classclsfy__logit__loss__function.html#a7f9996082faccc77b71a60cc8068d502" title="Min probability (avoids log(zero)).">min_p_</a>;
<a name="l00032"></a>00032 
<a name="l00033"></a>00033   <span class="comment">//: Optional regularising function</span>
<a name="l00034"></a><a class="code" href="classclsfy__logit__loss__function.html#ad13f1acccd8eba4e0f88127b26a78e66">00034</a>   <a class="codeRef" doxygen="core_vnl.tag:../../../../core/vnl/html" href="../../../../core/vnl/html/classvnl__cost__function.html">vnl_cost_function</a> *<a class="code" href="classclsfy__logit__loss__function.html#ad13f1acccd8eba4e0f88127b26a78e66" title="Optional regularising function.">reg_fn_</a>;
<a name="l00035"></a>00035 <span class="keyword">public</span>:
<a name="l00036"></a>00036   <a class="code" href="classclsfy__logit__loss__function.html#ae08d8fd7b2b9eb374f159b094a661a55">clsfy_logit_loss_function</a>(<a class="codeRef" doxygen="contrib_mul_mbl.tag:../../../../contrib/mul/mbl/html" href="../../../../contrib/mul/mbl/html/classmbl__data__wrapper.html">mbl_data_wrapper</a>&lt;<a class="codeRef" doxygen="core_vnl.tag:../../../../core/vnl/html" href="../../../../core/vnl/html/classvnl__vector.html">vnl_vector&lt;double&gt;</a> &gt;&amp; x,
<a name="l00037"></a>00037                             <span class="keyword">const</span> <a class="codeRef" doxygen="core_vnl.tag:../../../../core/vnl/html" href="../../../../core/vnl/html/classvnl__vector.html">vnl_vector&lt;double&gt;</a> &amp; c,
<a name="l00038"></a>00038                             <span class="keywordtype">double</span> min_p, <a class="codeRef" doxygen="core_vnl.tag:../../../../core/vnl/html" href="../../../../core/vnl/html/classvnl__cost__function.html">vnl_cost_function</a>* reg_fn=0);
<a name="l00039"></a>00039 
<a name="l00040"></a>00040   <span class="comment">//:  The main function: Compute f(v)</span>
<a name="l00041"></a>00041   <span class="keyword">virtual</span> <span class="keywordtype">double</span> <a class="code" href="classclsfy__logit__loss__function.html#a58c2483d17585947b22cd03ac64ef2e3" title="The main function: Compute f(v).">f</a>(<a class="codeRef" doxygen="core_vnl.tag:../../../../core/vnl/html" href="../../../../core/vnl/html/classvnl__vector.html">vnl_vector&lt;double&gt;</a> <span class="keyword">const</span>&amp; v);
<a name="l00042"></a>00042 
<a name="l00043"></a>00043   <span class="comment">//:  Calculate the gradient of f at parameter vector v.</span>
<a name="l00044"></a>00044   <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classclsfy__logit__loss__function.html#add7cd2a3d07421dd8562a72db9d6c65d" title="Calculate the gradient of f at parameter vector v.">gradf</a>(<a class="codeRef" doxygen="core_vnl.tag:../../../../core/vnl/html" href="../../../../core/vnl/html/classvnl__vector.html">vnl_vector&lt;double&gt;</a> <span class="keyword">const</span>&amp; v, 
<a name="l00045"></a>00045                      <a class="codeRef" doxygen="core_vnl.tag:../../../../core/vnl/html" href="../../../../core/vnl/html/classvnl__vector.html">vnl_vector&lt;double&gt;</a>&amp; gradient);
<a name="l00046"></a>00046 
<a name="l00047"></a>00047   <span class="comment">//: Compute f(v) and its gradient (if non-zero pointers supplied)</span>
<a name="l00048"></a>00048   <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classclsfy__logit__loss__function.html#a58d883b87c4f1e3490963f18cd6ef97a" title="Compute f(v) and its gradient (if non-zero pointers supplied).">compute</a>(<a class="codeRef" doxygen="core_vnl.tag:../../../../core/vnl/html" href="../../../../core/vnl/html/classvnl__vector.html">vnl_vector&lt;double&gt;</a> <span class="keyword">const</span>&amp; v,
<a name="l00049"></a>00049                        <span class="keywordtype">double</span> *<a class="code" href="classclsfy__logit__loss__function.html#a58c2483d17585947b22cd03ac64ef2e3" title="The main function: Compute f(v).">f</a>, <a class="codeRef" doxygen="core_vnl.tag:../../../../core/vnl/html" href="../../../../core/vnl/html/classvnl__vector.html">vnl_vector&lt;double&gt;</a>* gradient);
<a name="l00050"></a>00050 
<a name="l00051"></a>00051 };
<a name="l00052"></a>00052 
<a name="l00053"></a>00053 <span class="comment">//: Simple quadratic term used to regularise functions</span>
<a name="l00054"></a>00054 <span class="comment">//  For vector v&#39; = (b w&#39;) (ie b=y[0], w=(y[1]...y[n])), computes</span>
<a name="l00055"></a>00055 <span class="comment">//  f(v) = alpha*|w|^2   (ie ignores first element, which is bias of linear classifier)</span>
<a name="l00056"></a><a class="code" href="classclsfy__quad__regulariser.html">00056</a> <span class="keyword">class </span><a class="code" href="classclsfy__quad__regulariser.html" title="Simple quadratic term used to regularise functions.">clsfy_quad_regulariser</a> : <span class="keyword">public</span> <a class="codeRef" doxygen="core_vnl.tag:../../../../core/vnl/html" href="../../../../core/vnl/html/classvnl__cost__function.html">vnl_cost_function</a>
<a name="l00057"></a>00057 {
<a name="l00058"></a>00058 <span class="keyword">private</span>:
<a name="l00059"></a>00059   <span class="comment">//: Scaling factor</span>
<a name="l00060"></a><a class="code" href="classclsfy__quad__regulariser.html#abe4f97d4d99a646e550f5c65de89bafe">00060</a>   <span class="keywordtype">double</span> <a class="code" href="classclsfy__quad__regulariser.html#abe4f97d4d99a646e550f5c65de89bafe" title="Scaling factor.">alpha_</a>;
<a name="l00061"></a>00061 <span class="keyword">public</span>:
<a name="l00062"></a>00062   <a class="code" href="classclsfy__quad__regulariser.html#ac71d9d8909c98ec3f8c48e3ee8011185">clsfy_quad_regulariser</a>(<span class="keywordtype">double</span> alpha=1e-6);
<a name="l00063"></a>00063 
<a name="l00064"></a>00064   <span class="comment">//:  The main function: Compute f(v)</span>
<a name="l00065"></a>00065   <span class="keyword">virtual</span> <span class="keywordtype">double</span> <a class="code" href="classclsfy__quad__regulariser.html#a4da0d71856ebf86b253618f5332914eb" title="The main function: Compute f(v).">f</a>(<a class="codeRef" doxygen="core_vnl.tag:../../../../core/vnl/html" href="../../../../core/vnl/html/classvnl__vector.html">vnl_vector&lt;double&gt;</a> <span class="keyword">const</span>&amp; v);
<a name="l00066"></a>00066 
<a name="l00067"></a>00067   <span class="comment">//:  Calculate the gradient of f at parameter vector v.</span>
<a name="l00068"></a>00068   <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classclsfy__quad__regulariser.html#aa141fa6a1e4e0b487926f5d3c6ba6633" title="Calculate the gradient of f at parameter vector v.">gradf</a>(<a class="codeRef" doxygen="core_vnl.tag:../../../../core/vnl/html" href="../../../../core/vnl/html/classvnl__vector.html">vnl_vector&lt;double&gt;</a> <span class="keyword">const</span>&amp; v, 
<a name="l00069"></a>00069                      <a class="codeRef" doxygen="core_vnl.tag:../../../../core/vnl/html" href="../../../../core/vnl/html/classvnl__vector.html">vnl_vector&lt;double&gt;</a>&amp; gradient);
<a name="l00070"></a>00070 };
<a name="l00071"></a>00071 
<a name="l00072"></a>00072 
<a name="l00073"></a>00073 <span class="preprocessor">#endif // clsfy_logit_loss_function_h_</span>
</pre></div></div>
</div>


<hr class="footer"/><address class="footer"><small>
Generated on Wed May 1 2013 17:33:41 for contrib/mul/clsfy by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.7.5.1
</small></address>

</body>
</html>
